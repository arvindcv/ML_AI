{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573b0d26",
   "metadata": {},
   "source": [
    "# <span style=\"color: blue;\">Model creation using Google Bert</span>\n",
    "#### <span style=\"color: gray;\"> Reference - Below link was taken as a reference to come up with the working model for tweet data.</span>\n",
    "##### https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095fb503",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Imports needed for Tensor flow to work</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770fc95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    code_show_err=false; \n",
       "    function code_toggle_err() {\n",
       "     if (code_show_err){\n",
       "     $('div.output_stderr').hide();\n",
       "     } else {\n",
       "     $('div.output_stderr').show();\n",
       "     }\n",
       "     code_show_err = !code_show_err\n",
       "    } \n",
       "    $( document ).ready(code_toggle_err);\n",
       "    </script>\n",
       "    To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "    code_show_err=false; \n",
    "    function code_toggle_err() {\n",
    "     if (code_show_err){\n",
    "     $('div.output_stderr').hide();\n",
    "     } else {\n",
    "     $('div.output_stderr').show();\n",
    "     }\n",
    "     code_show_err = !code_show_err\n",
    "    } \n",
    "    $( document ).ready(code_toggle_err);\n",
    "    </script>\n",
    "    To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b618808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b7d9590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c8fe8",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Imports needed for Tensor flow to work</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5570e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ipynb.fs.full.function import stemmer\n",
    "#from ipynb.fs.full.function import lemmetizer\n",
    "from ipynb.fs.full.function import print_model_data\n",
    "from ipynb.fs.full.function import model_execute\n",
    "from ipynb.fs.full.function import stemm_data\n",
    "from ipynb.fs.full.function import lemm_data\n",
    "from ipynb.fs.full.function import class_balancer\n",
    "from ipynb.fs.full.function import bar_plot\n",
    "from ipynb.fs.full.function import get_data\n",
    "from ipynb.fs.full.function import remove_punctuation_func\n",
    "from ipynb.fs.full.function import convert_data_to_examples\n",
    "from ipynb.fs.full.function import convert_examples_to_tf_dataset\n",
    "from ipynb.fs.full.function import get_live_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399be329",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Creating the model and tokenizer for Google Bert</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d54acc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f35894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389beb4c",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> Prepare the text for Google Bert to process the data into Bert Data Set. </span>\n",
    "# <span style=\"color: green;\"> Here the text column is loaded iteratively and saved in a new column replaced with a ', ' </span>\n",
    "# <span style=\"color: green;\">   at the end to mark end of one entry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a92dfbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0         1   \n",
       "1         4   \n",
       "2         5   \n",
       "3         6   \n",
       "4         7   \n",
       "...     ...   \n",
       "7608  10869   \n",
       "7609  10870   \n",
       "7610  10871   \n",
       "7611  10872   \n",
       "7612  10873   \n",
       "\n",
       "                                                                                                                                           text  \\\n",
       "0                                                                         Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                        Forest fire near La Ronge Sask. Canada   \n",
       "2         All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                             13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                                      Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "...                                                                                                                                         ...   \n",
       "7608                                                        Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5   \n",
       "7609              @aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.   \n",
       "7610                                                                          M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ   \n",
       "7611  Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.   \n",
       "7612                                             The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d   \n",
       "\n",
       "      target  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "7608       1  \n",
       "7609       1  \n",
       "7610       1  \n",
       "7611       1  \n",
       "7612       1  \n",
       "\n",
       "[7613 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('data/train.csv')\n",
    "tweets\n",
    "replaced = []\n",
    "text = tweets['text']\n",
    "\n",
    "# for i in text:\n",
    "#     replaced.append(i+\", \")\n",
    "    \n",
    "# tweets['replaced'] = replaced\n",
    "tweets = tweets.drop('keyword',axis=1).drop('location',axis=1)\n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba833a",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> Creating a postive Data Set for Google Bert</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c869bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3271 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0         1   \n",
       "1         4   \n",
       "2         5   \n",
       "3         6   \n",
       "4         7   \n",
       "...     ...   \n",
       "7608  10869   \n",
       "7609  10870   \n",
       "7610  10871   \n",
       "7611  10872   \n",
       "7612  10873   \n",
       "\n",
       "                                                                                                                                           text  \\\n",
       "0                                                                         Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                        Forest fire near La Ronge Sask. Canada   \n",
       "2         All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                             13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                                      Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "...                                                                                                                                         ...   \n",
       "7608                                                        Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5   \n",
       "7609              @aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.   \n",
       "7610                                                                          M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ   \n",
       "7611  Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.   \n",
       "7612                                             The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d   \n",
       "\n",
       "      target  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "7608       1  \n",
       "7609       1  \n",
       "7610       1  \n",
       "7611       1  \n",
       "7612       1  \n",
       "\n",
       "[3271 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives=''\n",
    "positives = tweets.query(\"`target`==1\")\n",
    "positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77488e9c",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> Creating a negative Data Set for Google Bert </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d820338e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>@engineshed Great atmosphere at the British Lion gig tonight. Hearing is wrecked. http://t.co/oMNBAtJEAO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>10834</td>\n",
       "      <td>Cramer: Iger's 3 words that wrecked Disney's stock - CNBC http://t.co/N6RBnHMTD4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>10837</td>\n",
       "      <td>These boxes are ready to explode! Exploding Kittens finally arrived! gameofkittens #explodingkittensÛ_ https://t.co/TFGrAyuDC5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>10841</td>\n",
       "      <td>Sirens everywhere!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>10848</td>\n",
       "      <td>I just heard a really loud bang and everyone is asleep great</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4342 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "15       23   \n",
       "16       24   \n",
       "17       25   \n",
       "18       26   \n",
       "19       28   \n",
       "...     ...   \n",
       "7581  10833   \n",
       "7582  10834   \n",
       "7584  10837   \n",
       "7587  10841   \n",
       "7593  10848   \n",
       "\n",
       "                                                                                                                                 text  \\\n",
       "15                                                                                                                     What's up man?   \n",
       "16                                                                                                                      I love fruits   \n",
       "17                                                                                                                   Summer is lovely   \n",
       "18                                                                                                                  My car is so fast   \n",
       "19                                                                                                       What a goooooooaaaaaal!!!!!!   \n",
       "...                                                                                                                               ...   \n",
       "7581                         @engineshed Great atmosphere at the British Lion gig tonight. Hearing is wrecked. http://t.co/oMNBAtJEAO   \n",
       "7582                                                 Cramer: Iger's 3 words that wrecked Disney's stock - CNBC http://t.co/N6RBnHMTD4   \n",
       "7584  These boxes are ready to explode! Exploding Kittens finally arrived! gameofkittens #explodingkittensÛ_ https://t.co/TFGrAyuDC5   \n",
       "7587                                                                                                               Sirens everywhere!   \n",
       "7593                                                                     I just heard a really loud bang and everyone is asleep great   \n",
       "\n",
       "      target  \n",
       "15         0  \n",
       "16         0  \n",
       "17         0  \n",
       "18         0  \n",
       "19         0  \n",
       "...      ...  \n",
       "7581       0  \n",
       "7582       0  \n",
       "7584       0  \n",
       "7587       0  \n",
       "7593       0  \n",
       "\n",
       "[4342 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negavites=''\n",
    "negatives = tweets.query(\"`target`==0\")\n",
    "negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c981a6",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> Save the replaced column into a file to feed it into Google Bert</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "910953a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in positives['text']:\n",
    "    filename='data/train/pos/pos'+str(count)+'.txt'\n",
    "    finalArray=np.array([i])\n",
    "    np.savetxt(filename, finalArray, fmt='%s')\n",
    "    count=count+1\n",
    "count=0\n",
    "for j in negatives['text']:\n",
    "    filename='data/train/neg/neg'+str(count)+'.txt'\n",
    "    finalArray=np.array([j])\n",
    "    np.savetxt(filename, finalArray, fmt='%s')\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a6b7e5",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> Google Bert needs a specific folder structure.</span>\n",
    "# <span style=\"color: green;\"> 1. Top level folder which is fed to the tensor flow pre processing </span>\n",
    "# <span style=\"color: green;\"> 2. multiple files for each of the class, in this case Postive and Negative. </span>\n",
    "# <span style=\"color: green;\"> Here a manual step of creating this folder structure is performed. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c759836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7614 files belonging to 2 classes.\n",
      "Using 6092 files for training.\n",
      "<TakeDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
      "Found 7614 files belonging to 2 classes.\n",
      "Using 1522 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train = tf.keras.preprocessing.text_dataset_from_directory('data/',batch_size=30000, validation_split=0.2, \n",
    "   subset='training', seed=123)\n",
    "\n",
    "print(train.take(1))\n",
    "test = tf.keras.preprocessing.text_dataset_from_directory('data/', batch_size=30000, validation_split=0.2, \n",
    "    subset='validation', seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d0a3db",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> Create a DataFrame from the Bert BatchDataSet</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e24f154d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA_COLUMN</th>\n",
       "      <th>LABEL_COLUMN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fire in Pisgah National Forest grows to 375 acres http://t.co/dao9AZEUcr\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tsunami - DVBBS &amp;amp; Borgeous (Arceen Festival Trap Remix) https://t.co/743JoqazrT via @YouTube\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ladies here's how to recover from a #date you totally BOMBED... according to men http://t.co/c5GGSZUGw1 http://t.co/2PiMg9BIcE\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mattcohen4fake Gamma Ray January Worlds Collide She Waits Be Me Wave Past Perfect Reunion Lucky Cool If I Come Over Hot Times...\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spokane authorities say they're struggling to solve arson cases like today's on Hamilton. http://t.co/Qbs2k01WzK http://t.co/mvLZIYsGLL\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 DATA_COLUMN  \\\n",
       "0                                                                 Fire in Pisgah National Forest grows to 375 acres http://t.co/dao9AZEUcr\\n   \n",
       "1                                         Tsunami - DVBBS &amp; Borgeous (Arceen Festival Trap Remix) https://t.co/743JoqazrT via @YouTube\\n   \n",
       "2           Ladies here's how to recover from a #date you totally BOMBED... according to men http://t.co/c5GGSZUGw1 http://t.co/2PiMg9BIcE\\n   \n",
       "3        @mattcohen4fake Gamma Ray January Worlds Collide She Waits Be Me Wave Past Perfect Reunion Lucky Cool If I Come Over Hot Times...\\n   \n",
       "4  Spokane authorities say they're struggling to solve arson cases like today's on Hamilton. http://t.co/Qbs2k01WzK http://t.co/mvLZIYsGLL\\n   \n",
       "\n",
       "  LABEL_COLUMN  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat=''\n",
    "train_lab=''\n",
    "for i in train.take(2):\n",
    "    train_feat = i[0].numpy()\n",
    "    train_lab = i[1].numpy()\n",
    "\n",
    "train = pd.DataFrame([train_feat, train_lab]).T\n",
    "train.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "train['DATA_COLUMN'] = train['DATA_COLUMN'].str.decode(\"utf-8\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0043a",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> Create the Test data in a similar way for our validation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec228ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA_COLUMN</th>\n",
       "      <th>LABEL_COLUMN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lunch for the crew is made. Night night it's been a long day! \\n~Peace~Love~Rescue~\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSJThinkTank: Ahead of tonight's #GOPDebate ColleenMNelson explains how a bad debate can derail a campaign: Û_ http://t.co/XyxTuACZvb\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y'all read 12000 Nigerian refugees repatriated from Cameroon http://t.co/aVwE1LBvhn\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aspiring musician &amp;amp; song writer shares her talent at the GMMBC Youth Explosion on this past Saturday. http://t.co/OmjMTU9kFG\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Latest: More homes razed by Northern California wildfire - http://t.co/R1CNSjUAYQ http://t.co/DQ1yLcrF9K\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                DATA_COLUMN  \\\n",
       "0                                                     Lunch for the crew is made. Night night it's been a long day! \\n~Peace~Love~Rescue~\\n   \n",
       "1  WSJThinkTank: Ahead of tonight's #GOPDebate ColleenMNelson explains how a bad debate can derail a campaign: Û_ http://t.co/XyxTuACZvb\\n   \n",
       "2                                                     y'all read 12000 Nigerian refugees repatriated from Cameroon http://t.co/aVwE1LBvhn\\n   \n",
       "3        Aspiring musician &amp; song writer shares her talent at the GMMBC Youth Explosion on this past Saturday. http://t.co/OmjMTU9kFG\\n   \n",
       "4                            The Latest: More homes razed by Northern California wildfire - http://t.co/R1CNSjUAYQ http://t.co/DQ1yLcrF9K\\n   \n",
       "\n",
       "  LABEL_COLUMN  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for j in test.take(2):\n",
    "    test_feat = j[0].numpy()\n",
    "    test_lab = j[1].numpy()\n",
    "\n",
    "test = pd.DataFrame([test_feat, test_lab]).T\n",
    "test.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "test['DATA_COLUMN'] = test['DATA_COLUMN'].str.decode(\"utf-8\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed627fee",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> Generate the Training and Validation Data </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddbf417e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/achandrasekhar/opt/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, 'DATA_COLUMN', 'LABEL_COLUMN')\n",
    "\n",
    "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_data = train_data.shuffle(100).batch(32).repeat(2)\n",
    "\n",
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f3e6b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset element_spec=({'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713c7c8",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> We will use Adam as our optimizer, CategoricalCrossentropy as our loss function, and SparseCategoricalAccuracy as our accuracy metric. Fine-tuning the model for 2 epochs will give us around 95% accuracy</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47d0394a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "382/382 [==============================] - 3501s 9s/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 1.4649e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "382/382 [==============================] - 3416s 9s/step - loss: 8.2430e-04 - accuracy: 0.9998 - val_loss: 5.6582e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3aaffab50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "\n",
    "model.fit(train_data, epochs=2, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ccb88d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "live_tweets=get_live_tweets()\n",
    "for tweet in live_tweets['tweets']:\n",
    "    sentences.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d2b9c",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\"> Use the model for predicting the sample data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee888a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @moonlitmuses: no but who gonna tell these two to they're setting the screen on fire with this act of theirs already 🔥🤌🏻\\n#Yrkkh \\nhttps:/…</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@planetjedward What so that you can be ruled by the EU ?\\nOut of the frying pan and into the fire 🤷‍♂️</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GIRtech INSA-2 Insulation Fire Brick, 2-Pack, for Kilns, Forges, Metal Clay Firing, Jewelry Soldering, 2370 °F Rated [ETFCUQN]\\n\\nhttps://t.co/gRNuLn4Eea</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @UltraLandlord: Another electric bike caught fire during charging. \\n\\nThe worst part about burning lithium batteries is that you can't pu…</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @TheJokerBhai: Listen and Learn \\nHope Everybody has seen this  #SushantSinghRajput𓃵 quick fire questions \\nBut Still Culprits Roam Free I…</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clarify through fight fire, what do you define success, you must\\nAn empire ـ⁦فاشونـ there isn't ے⁦ماكس⁩- . The only loss    ك̷و̷د̶⁩ ⁦̸خ̷ص̸م̴⁩  .   is the best part https://t.co/xegRixks00</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @neknekmo1819: Fuel To The Fire: A #SeKen AU\\n\\nKen is a former drag racing champion who met an accident which marred his dreams of racing…</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @SanFranMuso: @City_Press .@AngieMotshekga @DBE_SA you and your department are bloody useless. You have broken the schooling system and…</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @The_Gator1: @jay_fcb @MetaBeatOffl MetaBeat will spread like wild fire Even the blind will see MetBeat and hop on 🚀🚀\\n#MetaBeat \\n#METABE…</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THIS IS MY ULTIMATE and A clear version acapella of Namjoon's fire rapping is just 🤯🤯🤯🤯🤯🤯\\n\\n#NAMJOONDAY #OurEternalLeader #Namjoonthebestrapper https://t.co/yDUc8QdB8z</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @dbossvijayapur: Boss fans on fire 💥🤙\\n\\n#DBoss #Roberrt #BossOfSandalwood #ChallengingStarDarshan #BoxOfficeSultan #Kranti\\n@dasadarshan h…</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @Mfoka_Jobe: First thing that Adv Mkhwebane need to do as she enters the office ,she must fire that colonial clerk leading that office,w…</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RT @Sunny_Rajput87: #BrahmastraBoxOffice: Ranbir-Alia starrer sets Box Office on Fire, earns Rs 5 crore globally in Reality \\n\\nThis is Real…</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @ManGoneCrypto1: MetaBeat will spread like wild fire Even the blind will see MetBeat and hop on 🚀🚀\\n#MetaBeat \\n#METABEATNFT\\n#MAMAMOO \\n#ON…</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@Ma33432646Jenna Political program scientist capital TV measure fire over.</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                          tweets  \\\n",
       "0                                                 RT @moonlitmuses: no but who gonna tell these two to they're setting the screen on fire with this act of theirs already 🔥🤌🏻\\n#Yrkkh \\nhttps:/…   \n",
       "1                                                                                         @planetjedward What so that you can be ruled by the EU ?\\nOut of the frying pan and into the fire 🤷‍♂️   \n",
       "2                                      GIRtech INSA-2 Insulation Fire Brick, 2-Pack, for Kilns, Forges, Metal Clay Firing, Jewelry Soldering, 2370 °F Rated [ETFCUQN]\\n\\nhttps://t.co/gRNuLn4Eea   \n",
       "3                                                 RT @UltraLandlord: Another electric bike caught fire during charging. \\n\\nThe worst part about burning lithium batteries is that you can't pu…   \n",
       "4                                                 RT @TheJokerBhai: Listen and Learn \\nHope Everybody has seen this  #SushantSinghRajput𓃵 quick fire questions \\nBut Still Culprits Roam Free I…   \n",
       "5   Clarify through fight fire, what do you define success, you must\\nAn empire ـ⁦فاشونـ there isn't ے⁦ماكس⁩- . The only loss    ك̷و̷د̶⁩ ⁦̸خ̷ص̸م̴⁩  .   is the best part https://t.co/xegRixks00   \n",
       "6                                                 RT @neknekmo1819: Fuel To The Fire: A #SeKen AU\\n\\nKen is a former drag racing champion who met an accident which marred his dreams of racing…   \n",
       "7                                                    RT @SanFranMuso: @City_Press .@AngieMotshekga @DBE_SA you and your department are bloody useless. You have broken the schooling system and…   \n",
       "8                                                 RT @The_Gator1: @jay_fcb @MetaBeatOffl MetaBeat will spread like wild fire Even the blind will see MetBeat and hop on 🚀🚀\\n#MetaBeat \\n#METABE…   \n",
       "9                       THIS IS MY ULTIMATE and A clear version acapella of Namjoon's fire rapping is just 🤯🤯🤯🤯🤯🤯\\n\\n#NAMJOONDAY #OurEternalLeader #Namjoonthebestrapper https://t.co/yDUc8QdB8z   \n",
       "10                                               RT @dbossvijayapur: Boss fans on fire 💥🤙\\n\\n#DBoss #Roberrt #BossOfSandalwood #ChallengingStarDarshan #BoxOfficeSultan #Kranti\\n@dasadarshan h…   \n",
       "11                                                  RT @Mfoka_Jobe: First thing that Adv Mkhwebane need to do as she enters the office ,she must fire that colonial clerk leading that office,w…   \n",
       "12                                                 RT @Sunny_Rajput87: #BrahmastraBoxOffice: Ranbir-Alia starrer sets Box Office on Fire, earns Rs 5 crore globally in Reality \\n\\nThis is Real…   \n",
       "13                                              RT @ManGoneCrypto1: MetaBeat will spread like wild fire Even the blind will see MetBeat and hop on 🚀🚀\\n#MetaBeat \\n#METABEATNFT\\n#MAMAMOO \\n#ON…   \n",
       "14                                                                                                                    @Ma33432646Jenna Political program scientist capital TV measure fire over.   \n",
       "\n",
       "   preds  \n",
       "0    [1]  \n",
       "1    [1]  \n",
       "2    [1]  \n",
       "3    [1]  \n",
       "4    [1]  \n",
       "5    [1]  \n",
       "6    [1]  \n",
       "7    [1]  \n",
       "8    [1]  \n",
       "9    [1]  \n",
       "10   [1]  \n",
       "11   [1]  \n",
       "12   [1]  \n",
       "13   [1]  \n",
       "14   [1]  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=[]\n",
    "tf_batch = tokenizer(sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "tf_outputs = model(tf_batch)\n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "labels = ['0','1']\n",
    "label = tf.argmax(tf_predictions, axis=1)\n",
    "label = label.numpy()\n",
    "for i in range(len(live_tweets)):\n",
    "    preds.append(list(labels[label[i]]))\n",
    "live_tweets['preds']=preds\n",
    "live_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68920a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
