{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e72501",
   "metadata": {},
   "source": [
    "# <span style=\"color: blue;\">Helper Methods :-</span>\n",
    "\n",
    "### <span style=\"color: green;\">This file has the helper methods needed for building and running a model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d151077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    code_show_err=false; \n",
       "    function code_toggle_err() {\n",
       "     if (code_show_err){\n",
       "     $('div.output_stderr').hide();\n",
       "     } else {\n",
       "     $('div.output_stderr').show();\n",
       "     }\n",
       "     code_show_err = !code_show_err\n",
       "    } \n",
       "    $( document ).ready(code_toggle_err);\n",
       "    </script>\n",
       "    To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "    code_show_err=false; \n",
    "    function code_toggle_err() {\n",
    "     if (code_show_err){\n",
    "     $('div.output_stderr').hide();\n",
    "     } else {\n",
    "     $('div.output_stderr').show();\n",
    "     }\n",
    "     code_show_err = !code_show_err\n",
    "    } \n",
    "    $( document ).ready(code_toggle_err);\n",
    "    </script>\n",
    "    To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "065d3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "166c70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter feed related imports\n",
    "\n",
    "# For sending GET requests from the API\n",
    "import requests\n",
    "\n",
    "# For saving access tokens and for file management when creating and adding to the dataset\n",
    "import os\n",
    "\n",
    "# For dealing with json responses we receive from the API\n",
    "import json\n",
    "\n",
    "# For displaying the data after\n",
    "import pandas as pd\n",
    "\n",
    "# For saving the response data in CSV format\n",
    "import csv\n",
    "\n",
    "# For parsing the dates received from twitter in readable formats\n",
    "from datetime import datetime, timedelta\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "\n",
    "import pytz\n",
    "\n",
    "from pyrfc3339 import generate, parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae43997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from transformers import InputExample, InputFeatures\n",
    "from sklearn.base import TransformerMixin\n",
    "from ipynb.fs.full.TwitterFeed import get_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57b92eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data/train.csv')\n",
    "tweet=tweets[['text','target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae96a0a",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Method to print the bar graph based on data :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6993bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(data):\n",
    "    data.value_counts().sort_values().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969be89",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Method to apply text with Stemmer applied to it :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39877c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "    stemm = PorterStemmer()\n",
    "    return ' '.join([stemm.stem(w) for w in word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de432f3e",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Method to apply text with Lemmetizer applied to it :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95774d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmetizer(text):\n",
    "    lemmetizer=WordNetLemmatizer()\n",
    "    return ' '.join([lemmetizer.lemmatize(w) for w in word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c065bf",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Method to balance an imbalanced class:-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5fd605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balancer(X,y):\n",
    "    sampler = SMOTE(random_state=42,k_neighbors=2)\n",
    "    X1, y1 = sampler.fit_resample(X, y)\n",
    "    return X1,y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "77826555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/5g9q6dvj03n7h1pj6bhdjfkw0000gq/T/ipykernel_9424/2266130295.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['stemmer']=tweet.text.apply(stemmer)\n",
      "/var/folders/5f/5g9q6dvj03n7h1pj6bhdjfkw0000gq/T/ipykernel_9424/2266130295.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweet['lemmetizer']=tweet.text.apply(lemmetizer)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>stemmer</th>\n",
       "      <th>lemmetizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deed are the reason of thi # earthquak may...</td>\n",
       "      <td>Our Deeds are the Reason of this # earthquake ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la rong sask . canada</td>\n",
       "      <td>Forest fire near La Ronge Sask . Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all resid ask to 'shelter in place ' are be no...</td>\n",
       "      <td>All resident asked to 'shelter in place ' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 peopl receiv # wildfir evacu order in c...</td>\n",
       "      <td>13,000 people receive # wildfire evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent thi photo from rubi # alaska as ...</td>\n",
       "      <td>Just got sent this photo from Ruby # Alaska a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>two giant crane hold a bridg collaps into near...</td>\n",
       "      <td>Two giant crane holding a bridge collapse into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>@ aria_ahrari @ thetawniest the out of control...</td>\n",
       "      <td>@ aria_ahrary @ TheTawniest The out of control...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>m1.94 [ 01:04 utc ] ? 5km s of volcano hawaii ...</td>\n",
       "      <td>M1.94 [ 01:04 UTC ] ? 5km S of Volcano Hawaii ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>polic investig after an e-bik collid with a ca...</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>the latest : more home raze by northern califo...</td>\n",
       "      <td>The Latest : More Homes Razed by Northern Cali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                                stemmer  \\\n",
       "0     our deed are the reason of thi # earthquak may...   \n",
       "1                forest fire near la rong sask . canada   \n",
       "2     all resid ask to 'shelter in place ' are be no...   \n",
       "3     13,000 peopl receiv # wildfir evacu order in c...   \n",
       "4     just got sent thi photo from rubi # alaska as ...   \n",
       "...                                                 ...   \n",
       "7608  two giant crane hold a bridg collaps into near...   \n",
       "7609  @ aria_ahrari @ thetawniest the out of control...   \n",
       "7610  m1.94 [ 01:04 utc ] ? 5km s of volcano hawaii ...   \n",
       "7611  polic investig after an e-bik collid with a ca...   \n",
       "7612  the latest : more home raze by northern califo...   \n",
       "\n",
       "                                             lemmetizer  \n",
       "0     Our Deeds are the Reason of this # earthquake ...  \n",
       "1               Forest fire near La Ronge Sask . Canada  \n",
       "2     All resident asked to 'shelter in place ' are ...  \n",
       "3     13,000 people receive # wildfire evacuation or...  \n",
       "4     Just got sent this photo from Ruby # Alaska a ...  \n",
       "...                                                 ...  \n",
       "7608  Two giant crane holding a bridge collapse into...  \n",
       "7609  @ aria_ahrary @ TheTawniest The out of control...  \n",
       "7610  M1.94 [ 01:04 UTC ] ? 5km S of Volcano Hawaii ...  \n",
       "7611  Police investigating after an e-bike collided ...  \n",
       "7612  The Latest : More Homes Razed by Northern Cali...  \n",
       "\n",
       "[7613 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet['stemmer']=tweet.text.apply(stemmer)\n",
    "tweet['lemmetizer']=tweet.text.apply(lemmetizer)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adbd8fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tweet.drop('target',axis=1)\n",
    "y=tweet['target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6896cf8",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Method to return the train and test data with stemmer applied text :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63464063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemm_data():\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X['stemmer'],y,test_size=0.25,random_state=42)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c258117",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Method to return the train and test data with stemmer applied text :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f05f83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_data():\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X['lemmetizer'],y,test_size=0.25,random_state=42)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcabf09",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Helper Method to return the data loaded :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f81f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd5b48",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">The data frame to collect the metrics data :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bc8f2b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   model           0 non-null      object\n",
      " 1   best_params     0 non-null      object\n",
      " 2   best_score      0 non-null      object\n",
      " 3   best_time       0 non-null      object\n",
      " 4   accuracy_score  0 non-null      object\n",
      " 5   roc_auc_score   0 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 124.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "comparison= pd.DataFrame({'model': [], \n",
    "             'best_params': [],\n",
    "             'best_score': [],\n",
    "             'best_time':[],\n",
    "             'accuracy_score':[],\n",
    "             'roc_auc_score':[]})\n",
    "comparison=comparison.astype(str)\n",
    "print(comparison.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7dbb4d",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Helper Method to fit the model and record the fit time :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fce115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_execute(model,X,y):\n",
    "    start=time.time()\n",
    "    model.fit(X,y)\n",
    "    end=time.time()\n",
    "    return end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca567b",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Helper Method to return the train and test data with stemmer applied text :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5209905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_data(name,time,model,X_train,X_test,y_train,y_test,is_grid,title='Confusion Matrix',cmap=plt.cm.Blues):\n",
    "    score = model.score(X_test,y_test)\n",
    "    model_param = model.get_params()\n",
    "    pred=model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    auc = roc_auc_score(y_test,pred)    \n",
    "    conf = metrics.ConfusionMatrixDisplay.from_predictions(y_test, pred)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicated label')\n",
    "    if(is_grid==True):\n",
    "        best_params=model.best_params_\n",
    "        comparison.loc[len(comparison.index)] = [name,best_params,score,time,accuracy,auc]\n",
    "    else:\n",
    "        comparison.loc[len(comparison.index)] = [name,model_param,score,time,accuracy,auc]\n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11ee09",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Helper Method to clean up the data for class balancing :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddfc206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanup_for_balancer_stemmer(X):\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    vectorizer.fit(X['stemmer'].values.ravel())\n",
    "\n",
    "    X_t=vectorizer.transform(X['stemmer'].values.ravel())\n",
    "\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_t,y,test_size=0.3,random_state=42)\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2251d1",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Helper Method to clean up the data for class balancing :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b8a29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanup_for_balancer_lemmetizer(X):\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    vectorizer.fit(X['lemmetizer'].values.ravel())\n",
    "\n",
    "    X_t=vectorizer.transform(X['lemmetizer'].values.ravel())\n",
    "\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_t,y,test_size=0.3,random_state=42)\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138064a",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Method to do the text cleaning:-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ded27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference https://michael-fuchs-python.netlify.app/2021/05/22/nlp-text-pre-processing-i-text-cleaning/#text-cleaning\n",
    "\n",
    "def remove_punctuation_func(text):\n",
    "    '''\n",
    "    Removes all punctuation from a string, if present\n",
    "    \n",
    "    Args:\n",
    "        text (str): String to which the function is to be applied, string\n",
    "    \n",
    "    Returns:\n",
    "        Clean string without punctuations\n",
    "    '''\n",
    "    return re.sub(r'[^a-zA-Z0-9]', ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a122f3",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Helper Method to work with Tensor Flow :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3251d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
    "    train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "    validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "  \n",
    "    return train_InputExamples, validation_InputExamples\n",
    "\n",
    "    train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \n",
    "                                                                           test, \n",
    "                                                                           'DATA_COLUMN', \n",
    "                                                                           'LABEL_COLUMN')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb5e07",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Helper method to work with Tensor flow :-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9a52ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_COLUMN = 'DATA_COLUMN'\n",
    "LABEL_COLUMN = 'LABEL_COLUMN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741bd7b3",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;\">Helper method to get live tweet data for the last 15 mins capped to 15 record:-</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c1db5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_live_tweets():\n",
    "    return get_tweets_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6a111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e40771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38230c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
